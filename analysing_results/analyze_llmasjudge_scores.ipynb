{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a212438-d3d8-47aa-acb9-d929e42bfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "malware =['00005BE947A8F108382B59CED7D1E95871A68539C00FF53FD3E1D93C58E2BA6C',\n",
    " '0000DA2338C5B466FC1A52AC2DA80DFCFC699E49FB3681A4468003AA204109B5',\n",
    " '0003175571B2548CF3A5DC42945AFABA2E486706BE51E4EEB0FB88D96C7B691D',\n",
    " '000345F1B90687FF298F4B0BB5DD09AB01FCCE2A8B58F9A901562A605D484B80',\n",
    " '0004D708768948DB3E79C2300368972EBED64C1FE6C0521A03A868188C122D2A',\n",
    " '00058E5CA57BA774DFB98B4661095F88E4DAA1A8E7A8D19B81D84D7E42868CFB',\n",
    " '00076CF9D074F00DEA55AF490B9EE8766F8E98382F070AFF6A02D15954DC6C9D',\n",
    " '0007DB1488BE0F1AE760BD9FEC68153DDEC6D692F3371A395D9F8822FFEC0935',\n",
    " '000947FD4D02DF36AB9508AF735BA7763330EF0FBA98710DA93050A92BDDB2A9',\n",
    " '00096875EADA8145C37C26A34A5BBF8F95F201E159C637E7CC8C5093C38967BA',\n",
    " '000AEF92243C36C5F4357E5121E74D1D9FD5579A6D1B3CFFEF2354817DED8541',\n",
    " '000BCFCB3991FE71555AE7D923C6AC59073626AFFFCC9DADDC7B73C0FED8046A',\n",
    " '000DF25B68D54B0D26C8E94B5FA8C5180B26EAE6A38EFD223E80B177BB27E6B0',\n",
    " '000EED8D67C7F6FAD37BCDE1F18EF90CD137D720FC96655142447B2B836AA4CB',\n",
    " '000FEED1F11E6C2BD606A1E0D1DFE7C110A98A275145FD5BBFE302C76078E826',\n",
    " '0013121BFDC7CC7E21401F95144EF56AF783F20477748E488725A1CFF68BB2B7',\n",
    " '001EF856699CBB1791EF2DEB00F66DD259491C332E0A8A4DC3ADF80531EBFF8B',\n",
    " '00217C8F76AAA8E5453BFC1269CB080A9A2F7F3D32480FC0C4A1EB99C22AFBAC',\n",
    " '002CFAA669F20C72304E25AEAE220B28DD9AA9C7CFDB9205EF9156F03AC252D1',\n",
    " '0035A5643659FA79FE081675C43476E8BCDD4634E2AB262D152E4FF7A3331BA5',\n",
    " '0035C98CEC406051345s0_DE5770AFBC9880C6512E2DE71D15E84CCC03A79EF3A38',\n",
    " '0035D4885301021E3C9F80EBBF040BCFFE61D64545B87ADBB039F915CC7F45D8',\n",
    " '0053A79C784D2283AC4601DA1DDD00AC947B57C1F4E303A6F42DD0700EC36A9D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25604df5-a45d-4a8d-bd6b-c181e35ca79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added column header 'output' to the first column in all CSV files successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Directory containing the CSV files\n",
    "folder_path = 'llmasjudge_summ'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = os.listdir(folder_path)\n",
    "\n",
    "\n",
    "\n",
    "# Filter the list to include only CSV files\n",
    "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "# Iterate through each CSV file and add a column header\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    # Rename the first column to 'output'\n",
    "    data.columns = ['output'] + list(data.columns[1:])\n",
    "    \n",
    "    # Save the updated DataFrame back to CSV\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Added column header 'output' to the first column in all CSV files successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fcda580-c683-4a83-9bc4-e29cd9e963da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed all CSV files and extracted text based on the specified pattern.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Directory containing the CSV files\n",
    "folder_path = 'llmasjudge_summ'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = os.listdir(folder_path)\n",
    "\n",
    "# Filter the list to include only CSV files\n",
    "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Define a function to extract text between [/INST] and </s> in the 'output' column\n",
    "    def extract_text(text):\n",
    "        match = re.search(r'\\[\\/INST\\](.*?)<\\/s>', text, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        return None\n",
    "    \n",
    "    # Apply the function to extract the relevant text from the 'output' column\n",
    "    if 'output' in data.columns:\n",
    "        data['extracted_text'] = data['output'].apply(extract_text)\n",
    "    else:\n",
    "        # If the first column is unnamed, assume it is the 'output' column\n",
    "        data.columns = ['output'] + list(data.columns[1:])\n",
    "        data['extracted_text'] = data['output'].apply(extract_text)\n",
    "    \n",
    "    # Save the updated DataFrame back to the same CSV file with the new column added\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Processed all CSV files and extracted text based on the specified pattern.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085cad02-4d2c-4c09-9a4b-bcf230fc6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/00005BE947A8F108382B59CED7D1E95871A68539C00FF53FD3E1D93C58E2BA6C_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0000DA2338C5B466FC1A52AC2DA80DFCFC699E49FB3681A4468003AA204109B5_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0003175571B2548CF3A5DC42945AFABA2E486706BE51E4EEB0FB88D96C7B691D_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/000345F1B90687FF298F4B0BB5DD09AB01FCCE2A8B58F9A901562A605D484B80_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0004D708768948DB3E79C2300368972EBED64C1FE6C0521A03A868188C122D2A_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/00058E5CA57BA774DFB98B4661095F88E4DAA1A8E7A8D19B81D84D7E42868CFB_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/00076CF9D074F00DEA55AF490B9EE8766F8E98382F070AFF6A02D15954DC6C9D_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0007DB1488BE0F1AE760BD9FEC68153DDEC6D692F3371A395D9F8822FFEC0935_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/000947FD4D02DF36AB9508AF735BA7763330EF0FBA98710DA93050A92BDDB2A9_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/00096875EADA8145C37C26A34A5BBF8F95F201E159C637E7CC8C5093C38967BA_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/000AEF92243C36C5F4357E5121E74D1D9FD5579A6D1B3CFFEF2354817DED8541_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/000BCFCB3991FE71555AE7D923C6AC59073626AFFFCC9DADDC7B73C0FED8046A_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/000DF25B68D54B0D26C8E94B5FA8C5180B26EAE6A38EFD223E80B177BB27E6B0_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/000EED8D67C7F6FAD37BCDE1F18EF90CD137D720FC96655142447B2B836AA4CB_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/000FEED1F11E6C2BD606A1E0D1DFE7C110A98A275145FD5BBFE302C76078E826_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0013121BFDC7CC7E21401F95144EF56AF783F20477748E488725A1CFF68BB2B7_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/001EF856699CBB1791EF2DEB00F66DD259491C332E0A8A4DC3ADF80531EBFF8B_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/00217C8F76AAA8E5453BFC1269CB080A9A2F7F3D32480FC0C4A1EB99C22AFBAC_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/002CFAA669F20C72304E25AEAE220B28DD9AA9C7CFDB9205EF9156F03AC252D1_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0035A5643659FA79FE081675C43476E8BCDD4634E2AB262D152E4FF7A3331BA5_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0035C98CEC406051345DE5770AFBC9880C6512E2DE71D15E84CCC03A79EF3A38_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0035D4885301021E3C9F80EBBF040BCFFE61D64545B87ADBB039F915CC7F45D8_r5_consistency.csv successfully.\n",
      "Consistency scores extracted and added to the CSV file temp_output_2_llmasjudge_r5/0053A79C784D2283AC4601DA1DDD00AC947B57C1F4E303A6F42DD0700EC36A9D_r5_consistency.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "# get CONSISTENCY score for outputs\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_consistency_score(text):\n",
    "    match = re.search(r'(\\d)/5|(\\d) out of|score of (\\d)', str(text), re.IGNORECASE)\n",
    "    if match:\n",
    "        for group in match.groups():\n",
    "            if group is not None:\n",
    "                return int(group)\n",
    "    return None\n",
    "\n",
    "# Process each CSV file\n",
    "for x in malware:\n",
    "    csv_file = f'llmasjudge_r5/{x}_r5_consistency.csv'\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Extract coherence score and create a new column\n",
    "        df['consistency_score'] = df['extracted_text'].apply(extract_consistency_score)\n",
    "        \n",
    "        # Save the updated DataFrame back to CSV\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        \n",
    "        print(f\"Consistency scores extracted and added to the CSV file {csv_file} successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {csv_file} does not exist.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "79a750b9-6ec7-4b7c-b421-88eea26cce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n",
      "Fluency scores extracted and added to the CSV file successfully.\n"
     ]
    }
   ],
   "source": [
    "# get FLUENCY score for outputs\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_fluency_score(text):\n",
    "    match = re.search(r'(\\d)/3|(\\d) out of|score of (\\d)', str(text), re.IGNORECASE)\n",
    "    if match:\n",
    "        for group in match.groups():\n",
    "            if group is not None:\n",
    "                return int(group)\n",
    "    return None\n",
    "    \n",
    "# Load the CSV file\n",
    "for x in malware:\n",
    "    # file_path = \n",
    "    csv_file = f'llmasjudge_r3/{x}_r3_fluency.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    \n",
    "    # Extract coherence score and create a new column\n",
    "    df['fluency_score'] = df['extracted_text'].apply(extract_fluency_score)\n",
    "    \n",
    "    # Save the updated DataFrame back to CSV\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    print(\"Fluency scores extracted and added to the CSV file successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dee81d5a-cb10-43d8-88f8-a797e5bb7e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n",
      "relevance scores extracted and added to the CSV file successfully.\n"
     ]
    }
   ],
   "source": [
    "# get RELEVANCE score for outputs\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_relevance_score(text):\n",
    "    match = re.search(r'(\\d)/5|(\\d) out of|score of (\\d)', str(text), re.IGNORECASE)\n",
    "    if match:\n",
    "        for group in match.groups():\n",
    "            if group is not None:\n",
    "                return int(group)\n",
    "    return None\n",
    "    \n",
    "# Load the CSV file\n",
    "for x in malware:\n",
    "    # file_path = \n",
    "    csv_file = f'llmasjudge_r3/{x}_r3_relevance.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # # Remove the 'coherence_score' column if it exists\n",
    "    # if 'coherence_score' in df.columns:\n",
    "    #     df = df.drop(columns=['coherence_score'])\n",
    "    \n",
    "    # Extract coherence score and create a new column\n",
    "    df['relevance_score'] = df['extracted_text'].apply(extract_relevance_score)\n",
    "    \n",
    "    # Save the updated DataFrame back to CSV\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    print(\"relevance scores extracted and added to the CSV file successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "788b0a83-2f9e-449b-b881-bba34e788b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n",
      "coherence scores extracted and added to the CSV file successfully.\n"
     ]
    }
   ],
   "source": [
    "# get COHERENCE score for outputs\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_coherence_score(text):\n",
    "    match = re.search(r'(\\d)/5|(\\d) out of|score of (\\d)', str(text), re.IGNORECASE)\n",
    "    if match:\n",
    "        for group in match.groups():\n",
    "            if group is not None:\n",
    "                return int(group)\n",
    "    return None\n",
    "    \n",
    "# Load the CSV file\n",
    "for x in malware:\n",
    "    # file_path = \n",
    "    csv_file = f'llmasjudge_r3/{x}_r3_coherence.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # # Remove the 'coherence_score' column if it exists\n",
    "    # if 'coherence_score' in df.columns:\n",
    "    #     df = df.drop(columns=['coherence_score'])\n",
    "    \n",
    "    # Extract coherence score and create a new column\n",
    "    df['coherence_score'] = df['extracted_text'].apply(extract_coherence_score)\n",
    "    \n",
    "    # Save the updated DataFrame back to CSV\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    print(\"coherence scores extracted and added to the CSV file successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c562782-2b5b-4815-92ce-47f6b605746e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1b66824-e95f-416a-8472-39b08d1aede0",
   "metadata": {},
   "source": [
    "get the mean score for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773aae6a-0442-4931-9457-7e863c35a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score of the 'consistency_score' for 00005BE947A8F108382B59CED7D1E95871A68539C00FF53FD3E1D93C58E2BA6C is: 4.000\n",
      "The mean score of the 'consistency_score' for 0000DA2338C5B466FC1A52AC2DA80DFCFC699E49FB3681A4468003AA204109B5 is: 4.000\n",
      "The mean score of the 'consistency_score' for 0003175571B2548CF3A5DC42945AFABA2E486706BE51E4EEB0FB88D96C7B691D is: 4.000\n",
      "The mean score of the 'consistency_score' for 000345F1B90687FF298F4B0BB5DD09AB01FCCE2A8B58F9A901562A605D484B80 is: 4.000\n",
      "The mean score of the 'consistency_score' for 0004D708768948DB3E79C2300368972EBED64C1FE6C0521A03A868188C122D2A is: 4.000\n",
      "The mean score of the 'consistency_score' for 00058E5CA57BA774DFB98B4661095F88E4DAA1A8E7A8D19B81D84D7E42868CFB is: 4.000\n",
      "The mean score of the 'consistency_score' for 00076CF9D074F00DEA55AF490B9EE8766F8E98382F070AFF6A02D15954DC6C9D is: 4.000\n",
      "The mean score of the 'consistency_score' for 0007DB1488BE0F1AE760BD9FEC68153DDEC6D692F3371A395D9F8822FFEC0935 is: 4.000\n",
      "The mean score of the 'consistency_score' for 000947FD4D02DF36AB9508AF735BA7763330EF0FBA98710DA93050A92BDDB2A9 is: 4.000\n",
      "The mean score of the 'consistency_score' for 00096875EADA8145C37C26A34A5BBF8F95F201E159C637E7CC8C5093C38967BA is: 4.000\n",
      "The mean score of the 'consistency_score' for 000AEF92243C36C5F4357E5121E74D1D9FD5579A6D1B3CFFEF2354817DED8541 is: 3.994\n",
      "The mean score of the 'consistency_score' for 000BCFCB3991FE71555AE7D923C6AC59073626AFFFCC9DADDC7B73C0FED8046A is: 4.000\n",
      "The mean score of the 'consistency_score' for 000DF25B68D54B0D26C8E94B5FA8C5180B26EAE6A38EFD223E80B177BB27E6B0 is: 4.000\n",
      "The mean score of the 'consistency_score' for 000EED8D67C7F6FAD37BCDE1F18EF90CD137D720FC96655142447B2B836AA4CB is: 4.000\n",
      "The mean score of the 'consistency_score' for 000FEED1F11E6C2BD606A1E0D1DFE7C110A98A275145FD5BBFE302C76078E826 is: 4.000\n",
      "The mean score of the 'consistency_score' for 0013121BFDC7CC7E21401F95144EF56AF783F20477748E488725A1CFF68BB2B7 is: 3.985\n",
      "The mean score of the 'consistency_score' for 001EF856699CBB1791EF2DEB00F66DD259491C332E0A8A4DC3ADF80531EBFF8B is: 4.000\n",
      "The mean score of the 'consistency_score' for 00217C8F76AAA8E5453BFC1269CB080A9A2F7F3D32480FC0C4A1EB99C22AFBAC is: 4.000\n",
      "The mean score of the 'consistency_score' for 002CFAA669F20C72304E25AEAE220B28DD9AA9C7CFDB9205EF9156F03AC252D1 is: 4.000\n",
      "The mean score of the 'consistency_score' for 0035A5643659FA79FE081675C43476E8BCDD4634E2AB262D152E4FF7A3331BA5 is: 4.000\n",
      "The mean score of the 'consistency_score' for 0035C98CEC406051345DE5770AFBC9880C6512E2DE71D15E84CCC03A79EF3A38 is: 4.000\n",
      "The mean score of the 'consistency_score' for 0035D4885301021E3C9F80EBBF040BCFFE61D64545B87ADBB039F915CC7F45D8 is: 4.000\n",
      "The mean score of the 'consistency_score' for 0053A79C784D2283AC4601DA1DDD00AC947B57C1F4E303A6F42DD0700EC36A9D is: 4.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '3.994',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '3.985',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean CONSISTENCY score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "consistency = []\n",
    "for x in malware:\n",
    "    # file_path = \n",
    "    csv_file = f'llmasjudge_r5/{x}_r5_consistency.csv'\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Calculate the mean score of the 'consistency_score' column\n",
    "        if 'consistency_score' in data.columns:\n",
    "            mean_score = data['consistency_score'].mean()\n",
    "            consistency.append(f'{mean_score:.3f}')\n",
    "            print(f\"The mean score of the 'consistency_score' for {x} is: {mean_score:.3f}\")\n",
    "        else:\n",
    "            print(f\"The column 'consistency_score' does not exist in the CSV file for {x}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {csv_file} does not exist.\")\n",
    "\n",
    "consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8172f3-0895-4caf-860d-9e86a4c83c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score of the 'fluency_score' for 00005BE947A8F108382B59CED7D1E95871A68539C00FF53FD3E1D93C58E2BA6C is: 4.000\n",
      "The mean score of the 'fluency_score' for 0000DA2338C5B466FC1A52AC2DA80DFCFC699E49FB3681A4468003AA204109B5 is: 4.000\n",
      "The mean score of the 'fluency_score' for 0003175571B2548CF3A5DC42945AFABA2E486706BE51E4EEB0FB88D96C7B691D is: 4.000\n",
      "The mean score of the 'fluency_score' for 000345F1B90687FF298F4B0BB5DD09AB01FCCE2A8B58F9A901562A605D484B80 is: 4.000\n",
      "The mean score of the 'fluency_score' for 0004D708768948DB3E79C2300368972EBED64C1FE6C0521A03A868188C122D2A is: 3.933\n",
      "The mean score of the 'fluency_score' for 00058E5CA57BA774DFB98B4661095F88E4DAA1A8E7A8D19B81D84D7E42868CFB is: 3.875\n",
      "The mean score of the 'fluency_score' for 00076CF9D074F00DEA55AF490B9EE8766F8E98382F070AFF6A02D15954DC6C9D is: 4.000\n",
      "The mean score of the 'fluency_score' for 0007DB1488BE0F1AE760BD9FEC68153DDEC6D692F3371A395D9F8822FFEC0935 is: 4.000\n",
      "The mean score of the 'fluency_score' for 000947FD4D02DF36AB9508AF735BA7763330EF0FBA98710DA93050A92BDDB2A9 is: 3.923\n",
      "The mean score of the 'fluency_score' for 00096875EADA8145C37C26A34A5BBF8F95F201E159C637E7CC8C5093C38967BA is: 4.000\n",
      "The mean score of the 'fluency_score' for 000AEF92243C36C5F4357E5121E74D1D9FD5579A6D1B3CFFEF2354817DED8541 is: 3.963\n",
      "The mean score of the 'fluency_score' for 000BCFCB3991FE71555AE7D923C6AC59073626AFFFCC9DADDC7B73C0FED8046A is: 4.000\n",
      "The mean score of the 'fluency_score' for 000DF25B68D54B0D26C8E94B5FA8C5180B26EAE6A38EFD223E80B177BB27E6B0 is: 4.000\n",
      "The mean score of the 'fluency_score' for 000EED8D67C7F6FAD37BCDE1F18EF90CD137D720FC96655142447B2B836AA4CB is: 4.000\n",
      "The mean score of the 'fluency_score' for 000FEED1F11E6C2BD606A1E0D1DFE7C110A98A275145FD5BBFE302C76078E826 is: 4.000\n",
      "The mean score of the 'fluency_score' for 0013121BFDC7CC7E21401F95144EF56AF783F20477748E488725A1CFF68BB2B7 is: 4.000\n",
      "The mean score of the 'fluency_score' for 001EF856699CBB1791EF2DEB00F66DD259491C332E0A8A4DC3ADF80531EBFF8B is: 4.000\n",
      "The mean score of the 'fluency_score' for 00217C8F76AAA8E5453BFC1269CB080A9A2F7F3D32480FC0C4A1EB99C22AFBAC is: 3.833\n",
      "The mean score of the 'fluency_score' for 002CFAA669F20C72304E25AEAE220B28DD9AA9C7CFDB9205EF9156F03AC252D1 is: 4.000\n",
      "The mean score of the 'fluency_score' for 0035A5643659FA79FE081675C43476E8BCDD4634E2AB262D152E4FF7A3331BA5 is: 3.929\n",
      "The mean score of the 'fluency_score' for 0035C98CEC406051345DE5770AFBC9880C6512E2DE71D15E84CCC03A79EF3A38 is: 4.000\n",
      "The mean score of the 'fluency_score' for 0035D4885301021E3C9F80EBBF040BCFFE61D64545B87ADBB039F915CC7F45D8 is: 4.000\n",
      "The mean score of the 'fluency_score' for 0053A79C784D2283AC4601DA1DDD00AC947B57C1F4E303A6F42DD0700EC36A9D is: 3.923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '3.933',\n",
       " '3.875',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '3.923',\n",
       " '4.000',\n",
       " '3.963',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '3.833',\n",
       " '4.000',\n",
       " '3.929',\n",
       " '4.000',\n",
       " '4.000',\n",
       " '3.923']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean FLUENCY score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fluency = []\n",
    "for x in malware:\n",
    "    # file_path = \n",
    "    csv_file = f'llmasjudge_r5/{x}_r5_fluency.csv'\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Calculate the mean score of the 'fluency_score' column\n",
    "        if 'fluency_score' in data.columns:\n",
    "            mean_score = data['fluency_score'].mean()\n",
    "            fluency.append(f'{mean_score:.3f}')\n",
    "            print(f\"The mean score of the 'fluency_score' for {x} is: {mean_score:.3f}\")\n",
    "        else:\n",
    "            print(f\"The column 'fluency_score' does not exist in the CSV file for {x}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {csv_file} does not exist.\")\n",
    "\n",
    "fluency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4826b046-980e-4f67-97e4-0d8d72f92f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score of the 'relevance_score' for 00005BE947A8F108382B59CED7D1E95871A68539C00FF53FD3E1D93C58E2BA6C is: 3.097\n",
      "The mean score of the 'relevance_score' for 0000DA2338C5B466FC1A52AC2DA80DFCFC699E49FB3681A4468003AA204109B5 is: 3.083\n",
      "The mean score of the 'relevance_score' for 0003175571B2548CF3A5DC42945AFABA2E486706BE51E4EEB0FB88D96C7B691D is: 3.048\n",
      "The mean score of the 'relevance_score' for 000345F1B90687FF298F4B0BB5DD09AB01FCCE2A8B58F9A901562A605D484B80 is: 3.133\n",
      "The mean score of the 'relevance_score' for 0004D708768948DB3E79C2300368972EBED64C1FE6C0521A03A868188C122D2A is: 3.000\n",
      "The mean score of the 'relevance_score' for 00058E5CA57BA774DFB98B4661095F88E4DAA1A8E7A8D19B81D84D7E42868CFB is: 3.089\n",
      "The mean score of the 'relevance_score' for 00076CF9D074F00DEA55AF490B9EE8766F8E98382F070AFF6A02D15954DC6C9D is: 3.066\n",
      "The mean score of the 'relevance_score' for 0007DB1488BE0F1AE760BD9FEC68153DDEC6D692F3371A395D9F8822FFEC0935 is: 3.036\n",
      "The mean score of the 'relevance_score' for 000947FD4D02DF36AB9508AF735BA7763330EF0FBA98710DA93050A92BDDB2A9 is: 3.022\n",
      "The mean score of the 'relevance_score' for 00096875EADA8145C37C26A34A5BBF8F95F201E159C637E7CC8C5093C38967BA is: 3.047\n",
      "The mean score of the 'relevance_score' for 000AEF92243C36C5F4357E5121E74D1D9FD5579A6D1B3CFFEF2354817DED8541 is: 3.041\n",
      "The mean score of the 'relevance_score' for 000BCFCB3991FE71555AE7D923C6AC59073626AFFFCC9DADDC7B73C0FED8046A is: 3.000\n",
      "The mean score of the 'relevance_score' for 000DF25B68D54B0D26C8E94B5FA8C5180B26EAE6A38EFD223E80B177BB27E6B0 is: 3.000\n",
      "The mean score of the 'relevance_score' for 000EED8D67C7F6FAD37BCDE1F18EF90CD137D720FC96655142447B2B836AA4CB is: 3.062\n",
      "The mean score of the 'relevance_score' for 000FEED1F11E6C2BD606A1E0D1DFE7C110A98A275145FD5BBFE302C76078E826 is: 3.067\n",
      "The mean score of the 'relevance_score' for 0013121BFDC7CC7E21401F95144EF56AF783F20477748E488725A1CFF68BB2B7 is: 3.031\n",
      "The mean score of the 'relevance_score' for 001EF856699CBB1791EF2DEB00F66DD259491C332E0A8A4DC3ADF80531EBFF8B is: 3.015\n",
      "The mean score of the 'relevance_score' for 00217C8F76AAA8E5453BFC1269CB080A9A2F7F3D32480FC0C4A1EB99C22AFBAC is: 3.000\n",
      "The mean score of the 'relevance_score' for 002CFAA669F20C72304E25AEAE220B28DD9AA9C7CFDB9205EF9156F03AC252D1 is: 3.000\n",
      "The mean score of the 'relevance_score' for 0035A5643659FA79FE081675C43476E8BCDD4634E2AB262D152E4FF7A3331BA5 is: 3.015\n",
      "The mean score of the 'relevance_score' for 0035C98CEC406051345DE5770AFBC9880C6512E2DE71D15E84CCC03A79EF3A38 is: 3.111\n",
      "The mean score of the 'relevance_score' for 0035D4885301021E3C9F80EBBF040BCFFE61D64545B87ADBB039F915CC7F45D8 is: 3.047\n",
      "The mean score of the 'relevance_score' for 0053A79C784D2283AC4601DA1DDD00AC947B57C1F4E303A6F42DD0700EC36A9D is: 3.095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3.097',\n",
       " '3.083',\n",
       " '3.048',\n",
       " '3.133',\n",
       " '3.000',\n",
       " '3.089',\n",
       " '3.066',\n",
       " '3.036',\n",
       " '3.022',\n",
       " '3.047',\n",
       " '3.041',\n",
       " '3.000',\n",
       " '3.000',\n",
       " '3.062',\n",
       " '3.067',\n",
       " '3.031',\n",
       " '3.015',\n",
       " '3.000',\n",
       " '3.000',\n",
       " '3.015',\n",
       " '3.111',\n",
       " '3.047',\n",
       " '3.095']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean RELEVANCE score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "relevance = []\n",
    "for x in malware:\n",
    "    # file_path = \n",
    "    csv_file = f'llmasjudge_r5/{x}_r5_relevance.csv'\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Calculate the mean score of the 'relevance_score' column\n",
    "        if 'relevance_score' in data.columns:\n",
    "            mean_score = data['relevance_score'].mean()\n",
    "            relevance.append(f'{mean_score:.3f}')\n",
    "            print(f\"The mean score of the 'relevance_score' for {x} is: {mean_score:.3f}\")\n",
    "        else:\n",
    "            print(f\"The column 'relevance_score' does not exist in the CSV file for {x}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {csv_file} does not exist.\")\n",
    "\n",
    "relevance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5f1013-31a5-44ac-bfc6-2d328079c188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score of the 'coherence_score' for 00005BE947A8F108382B59CED7D1E95871A68539C00FF53FD3E1D93C58E2BA6C is: 4.483\n",
      "The mean score of the 'coherence_score' for 0000DA2338C5B466FC1A52AC2DA80DFCFC699E49FB3681A4468003AA204109B5 is: 4.500\n",
      "The mean score of the 'coherence_score' for 0003175571B2548CF3A5DC42945AFABA2E486706BE51E4EEB0FB88D96C7B691D is: 4.348\n",
      "The mean score of the 'coherence_score' for 000345F1B90687FF298F4B0BB5DD09AB01FCCE2A8B58F9A901562A605D484B80 is: 4.531\n",
      "The mean score of the 'coherence_score' for 0004D708768948DB3E79C2300368972EBED64C1FE6C0521A03A868188C122D2A is: 4.877\n",
      "The mean score of the 'coherence_score' for 00058E5CA57BA774DFB98B4661095F88E4DAA1A8E7A8D19B81D84D7E42868CFB is: 4.615\n",
      "The mean score of the 'coherence_score' for 00076CF9D074F00DEA55AF490B9EE8766F8E98382F070AFF6A02D15954DC6C9D is: 4.318\n",
      "The mean score of the 'coherence_score' for 0007DB1488BE0F1AE760BD9FEC68153DDEC6D692F3371A395D9F8822FFEC0935 is: 4.542\n",
      "The mean score of the 'coherence_score' for 000947FD4D02DF36AB9508AF735BA7763330EF0FBA98710DA93050A92BDDB2A9 is: 4.922\n",
      "The mean score of the 'coherence_score' for 00096875EADA8145C37C26A34A5BBF8F95F201E159C637E7CC8C5093C38967BA is: 4.409\n",
      "The mean score of the 'coherence_score' for 000AEF92243C36C5F4357E5121E74D1D9FD5579A6D1B3CFFEF2354817DED8541 is: 4.665\n",
      "The mean score of the 'coherence_score' for 000BCFCB3991FE71555AE7D923C6AC59073626AFFFCC9DADDC7B73C0FED8046A is: 4.833\n",
      "The mean score of the 'coherence_score' for 000DF25B68D54B0D26C8E94B5FA8C5180B26EAE6A38EFD223E80B177BB27E6B0 is: 4.625\n",
      "The mean score of the 'coherence_score' for 000EED8D67C7F6FAD37BCDE1F18EF90CD137D720FC96655142447B2B836AA4CB is: 4.677\n",
      "The mean score of the 'coherence_score' for 000FEED1F11E6C2BD606A1E0D1DFE7C110A98A275145FD5BBFE302C76078E826 is: 4.583\n",
      "The mean score of the 'coherence_score' for 0013121BFDC7CC7E21401F95144EF56AF783F20477748E488725A1CFF68BB2B7 is: 4.590\n",
      "The mean score of the 'coherence_score' for 001EF856699CBB1791EF2DEB00F66DD259491C332E0A8A4DC3ADF80531EBFF8B is: 4.571\n",
      "The mean score of the 'coherence_score' for 00217C8F76AAA8E5453BFC1269CB080A9A2F7F3D32480FC0C4A1EB99C22AFBAC is: 3.000\n",
      "The mean score of the 'coherence_score' for 002CFAA669F20C72304E25AEAE220B28DD9AA9C7CFDB9205EF9156F03AC252D1 is: 4.900\n",
      "The mean score of the 'coherence_score' for 0035A5643659FA79FE081675C43476E8BCDD4634E2AB262D152E4FF7A3331BA5 is: 4.536\n",
      "The mean score of the 'coherence_score' for 0035C98CEC406051345DE5770AFBC9880C6512E2DE71D15E84CCC03A79EF3A38 is: 4.286\n",
      "The mean score of the 'coherence_score' for 0035D4885301021E3C9F80EBBF040BCFFE61D64545B87ADBB039F915CC7F45D8 is: 4.333\n",
      "The mean score of the 'coherence_score' for 0053A79C784D2283AC4601DA1DDD00AC947B57C1F4E303A6F42DD0700EC36A9D is: 4.722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4.483',\n",
       " '4.500',\n",
       " '4.348',\n",
       " '4.531',\n",
       " '4.877',\n",
       " '4.615',\n",
       " '4.318',\n",
       " '4.542',\n",
       " '4.922',\n",
       " '4.409',\n",
       " '4.665',\n",
       " '4.833',\n",
       " '4.625',\n",
       " '4.677',\n",
       " '4.583',\n",
       " '4.590',\n",
       " '4.571',\n",
       " '3.000',\n",
       " '4.900',\n",
       " '4.536',\n",
       " '4.286',\n",
       " '4.333',\n",
       " '4.722']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean COHERENCE score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "coherence = []\n",
    "for x in malware:\n",
    "    # file_path = \n",
    "    csv_file = f'llmasjudge_r5/{x}_r5_coherence.csv'\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Calculate the mean score of the 'coherence_score' column\n",
    "        if 'coherence_score' in data.columns:\n",
    "            mean_score = data['coherence_score'].mean()\n",
    "            coherence.append(f'{mean_score:.3f}')\n",
    "            print(f\"The mean score of the 'coherence_score' for {x} is: {mean_score:.3f}\")\n",
    "        else:\n",
    "            print(f\"The column 'coherence_score' does not exist in the CSV file for {x}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {csv_file} does not exist.\")\n",
    "\n",
    "coherence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813f8c8-7428-4c4d-be5c-d20b4e925758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
